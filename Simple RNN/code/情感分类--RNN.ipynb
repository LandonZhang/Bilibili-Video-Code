{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:46.229241Z",
     "start_time": "2025-01-03T06:27:46.217253Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6c8c7225c8c655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:46.259759Z",
     "start_time": "2025-01-03T06:27:46.243090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ItemID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sentiment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SentimentSource",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SentimentText",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f59fe939-e844-48a7-bcb2-f70b0ccb5fc7",
       "rows": [
        [
         "0",
         "1",
         "0",
         "Sentiment140",
         "                     is so sad for my APL friend............."
        ],
        [
         "1",
         "2",
         "0",
         "Sentiment140",
         "                   I missed the New Moon trailer..."
        ],
        [
         "2",
         "3",
         "1",
         "Sentiment140",
         "              omg its already 7:30 :O"
        ],
        [
         "3",
         "4",
         "0",
         "Sentiment140",
         "          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)..."
        ],
        [
         "4",
         "5",
         "0",
         "Sentiment140",
         "         i think mi bf is cheating on me!!!       T_T"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "file_path = r\"../data/Sentiment Analysis Dataset.csv\"\n",
    "\n",
    "# 提取前1000条数据进行提取并训练\n",
    "data = pd.read_csv(file_path, encoding=\"utf-8\", on_bad_lines=\"skip\", nrows=1000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ec98625123e6858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:46.323410Z",
     "start_time": "2025-01-03T06:27:46.308411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         is so sad for my APL frie...\n",
       "1                       I missed the New Moon trail...\n",
       "2                              omg its already 7:30 :O\n",
       "3              .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4             i think mi bf is cheating on me!!!   ...\n",
       "Name: SentimentText, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取评论信息\n",
    "sentimentText = data[\"SentimentText\"]\n",
    "sentimentText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c40a2ebc6fc6d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:46.526686Z",
     "start_time": "2025-01-03T06:27:46.518182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# 获取真实的标签\n",
    "labels = torch.tensor(data[\"Sentiment\"])\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70eef57dc130d188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:46.762214Z",
     "start_time": "2025-01-03T06:27:46.724509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表的长度是: 3548\n",
      "Token数据中最大长度为: 31\n"
     ]
    }
   ],
   "source": [
    "# 对文本进行编码、分词的操作\n",
    "tokenizer = Tokenizer(num_words=1500, oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(sentimentText)  # 创建词汇表\n",
    "print(\"词汇表的长度是:\", len(tokenizer.word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentimentText)\n",
    "# print(sequences)  # 将文本数据转化为token序列化数据\n",
    "\n",
    "sequence_length = [len(sequence) for sequence in sequences]\n",
    "max_length = max(sequence_length)\n",
    "print(\"Token数据中最大长度为:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324bdb1295e38781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:46.888514Z",
     "start_time": "2025-01-03T06:27:46.875314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 31])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 将token数据转化成长度一致的序列便于处理\n",
    "padded_sequences = torch.tensor(\n",
    "    pad_sequences(sequences, maxlen=max_length), dtype=torch.long\n",
    ")\n",
    "print(padded_sequences.shape)\n",
    "print(padded_sequences.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b902ed9bc685f847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:47.012832Z",
     "start_time": "2025-01-03T06:27:47.005828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding操作后的形状为: torch.Size([1000, 31, 5])\n"
     ]
    }
   ],
   "source": [
    "# 对token化后的数据进行embedding操作\n",
    "embed_size = 5\n",
    "vocab_size = len(tokenizer.word_index)  # 获得词典长度，输入embedding层\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim=embed_size)  # 建立embedding层\n",
    "input = embedding(padded_sequences)\n",
    "print(\"Embedding操作后的形状为:\", input.shape)  # (batch_size, seq_len, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bd4aeedbd3479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:47.060832Z",
     "start_time": "2025-01-03T06:27:47.051832Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义多层RNN模型\n",
    "class MultiLayerRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, layer_num, class_num):\n",
    "        super(MultiLayerRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, layer_num, batch_first=True)\n",
    "        self.linear = nn.Linear(\n",
    "            hidden_size, class_num\n",
    "        )  # 由于使用的交叉熵损失自带softmax激活函数，故不再加激活曾\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs: 输入的embedding结果\n",
    "        :return: 返回最终的预测\n",
    "        \"\"\"\n",
    "        output, hidden = self.rnn(inputs)\n",
    "        final_hidden = hidden[-1]  # 获取最后一层RNN的最后一个时间步的隐藏层结果\n",
    "        linear_result = self.linear(final_hidden)\n",
    "        return linear_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20124b48c94660b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:47.092833Z",
     "start_time": "2025-01-03T06:27:47.081832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "# 设置参数值，并进行前向传播\n",
    "hidden_size = 6\n",
    "layer_num = 2\n",
    "class_num = 2\n",
    "\n",
    "# 定义RNN实例\n",
    "MyRNN = MultiLayerRNN(embed_size, hidden_size, layer_num, class_num)\n",
    "\n",
    "# 将embedding结果输入RNN网络，获取结果\n",
    "class_clarification = MyRNN(input)\n",
    "print(class_clarification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeac97fa772573c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T06:27:51.723696Z",
     "start_time": "2025-01-03T06:27:51.652667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6372, Accuracy: 66.80%\n",
      "Epoch [2/10], Loss: 0.6348, Accuracy: 66.80%\n",
      "Epoch [3/10], Loss: 0.6309, Accuracy: 66.80%\n",
      "Epoch [4/10], Loss: 0.6274, Accuracy: 66.80%\n",
      "Epoch [5/10], Loss: 0.6251, Accuracy: 66.80%\n",
      "Epoch [6/10], Loss: 0.6229, Accuracy: 66.80%\n",
      "Epoch [7/10], Loss: 0.6205, Accuracy: 67.30%\n",
      "Epoch [8/10], Loss: 0.6182, Accuracy: 68.20%\n",
      "Epoch [9/10], Loss: 0.6164, Accuracy: 68.80%\n",
      "Epoch [10/10], Loss: 0.6150, Accuracy: 69.10%\n"
     ]
    }
   ],
   "source": [
    "# 进行反向传播并优化\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(MyRNN.parameters(), lr=0.01)  # 定义优化器\n",
    "\n",
    "\n",
    "# 训练次数设置\n",
    "epochs = 10\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    embedded_input = embedding(padded_sequences)  # 每次循环重新生成embedding\n",
    "\n",
    "    # 前向传播\n",
    "    outputs = MyRNN(embedded_input)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 执行优化\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 计算准确率\n",
    "    with torch.no_grad():  # 禁用梯度计算以节省内存\n",
    "        predictions = torch.argmax(outputs, dim=1)  # 获取预测类别\n",
    "        correct = (predictions == labels).sum().item()  # 正确预测的数量\n",
    "        accuracy = correct / labels.size(0)  # 计算准确率\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # 打印损失和准确率\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy * 100:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ffb6fa452731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定模型保存规则\n",
    "if max(accuracy_list) >= 0.71:\n",
    "    torch.save(\n",
    "        MyRNN.state_dict(),\n",
    "        r\"../model/my_rnn_model.pth\",\n",
    "    )\n",
    "    print(\"RNN模型保存成功！\")\n",
    "else:\n",
    "    print(\"此次的模型没有达到标准\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635d595341f3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "loaded_model = MultiLayerRNN(embed_size, hidden_size, layer_num, class_num)\n",
    "loaded_model.load_state_dict(torch.load(r\"../model/my_rnn_model.pth\"))\n",
    "loaded_model.eval()  # 转化为评估模式"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
